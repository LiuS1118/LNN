import pandas as pd
import tensorflow as tf
from tensorflow.keras.layers import Dense, BatchNormalization, Dropout
import matplotlib.pyplot as plt
import numpy as np
from sklearn.model_selection import train_test_split

class NeuralNetworkModel(tf.keras.Model):
    def __init__(self, layers, output_size, alpha=0.5, dropout_rate=0.5, extra_bn_and_dropout=False):
        super(NeuralNetworkModel, self).__init__()
        self.alpha = alpha
        self.dense_layers = []
        for units in layers:
            self.dense_layers.append(Dense(units, activation=None))
            self.dense_layers.append(BatchNormalization())

            if extra_bn_and_dropout:
                self.dense_layers.append(BatchNormalization())
                self.dense_layers.append(Dropout(dropout_rate))
            
            self.dense_layers.append(tf.keras.layers.Lambda(lambda x: self.alpha * x))
            self.dense_layers.append(Dropout(dropout_rate))

            if extra_bn_and_dropout:
                self.dense_layers.append(BatchNormalization())
                self.dense_layers.append(Dropout(dropout_rate))

        self.output_layer = Dense(output_size)

    def call(self, inputs, training=False):
        x = inputs
        for layer in self.dense_layers:
            if isinstance(layer, (BatchNormalization, Dropout)):
                x = layer(x, training=training)
            else:
                x = layer(x)
        return self.output_layer(x)

# Example usage
model = NeuralNetworkModel(layers=[500, 500, 100, 500, 100, 500], output_size=500, dropout_rate=0.5, extra_bn_and_dropout=True)

def load_data():
    df_A = pd.read_csv('cbc_1.csv', index_col=False, keep_default_na=False, skip_blank_lines=True)
    A_matrix = df_A.iloc[0:500, 0:20].to_numpy().T
    A = tf.constant(A_matrix, dtype=tf.float32)

    df_f = pd.read_csv('f1.csv', index_col=False, keep_default_na=False, skip_blank_lines=True)
    f_matrix = df_f.iloc[0:500, 0:20].to_numpy().T
    f = tf.constant(f_matrix, dtype=tf.float32)

    return A, f

def preprocess_data():
    X_data = np.random.randn(20,500).astype(np.float32)
    X_normalized = (X_data - np.mean(X_data)) / np.std(X_data)
    X = tf.constant(X_normalized, dtype=tf.float32)
    return X
# 数据缩放因子
    scaling_factor = 10.9

def compute_loss(model, X, f, lambda_l1=0.000001, lambda_l2=0.000009, training=False):
    logits = model(X, training=training)
    mse_loss = tf.reduce_mean(tf.square(f - logits))
    l1_loss = tf.add_n([tf.reduce_sum(tf.abs(var)) for var in model.trainable_variables])
    l2_loss = tf.add_n([tf.reduce_sum(tf.square(var)) for var in model.trainable_variables])
    loss_value = mse_loss + lambda_l1 * l1_loss + lambda_l2 * l2_loss
    return loss_value

def compute_loss_and_grads(model, X, f, lambda_l1=0.000001, lambda_l2=0.000009):
    with tf.GradientTape() as tape:
        loss_value = compute_loss(model, X, f, lambda_l1, lambda_l2, training=True)
    grads = tape.gradient(loss_value, model.trainable_variables)
    return loss_value, grads

def compute_train_loss(model, X_train, f_train, lambda_l1=0.000001, lambda_l2=0.000009, training=False):
    return compute_loss(model, X_train, f_train, lambda_l1, lambda_l2, training)

def compute_train_loss_and_grads(model, X_train, f_train, lambda_l1=0.000001, lambda_l2=0.000009):
    with tf.GradientTape() as tape:
        train_loss_value = compute_train_loss(model, X_train, f_train, lambda_l1, lambda_l2, training=True)
    grads = tape.gradient(train_loss_value, model.trainable_variables)
    return train_loss_value, grads


def train_and_evaluate_mse_with_early_stopping(model, X, f, X_train, f_train, X_val, f_val, optimizer, num_epochs=5000, lambda_l1=0.000001, lambda_l2=0.000009):
    loss_values, train_loss_values, val_loss_values = [], [], []
    best_val_loss = np.inf
    epochs_without_improvement = 0
    patience = 500

    for epoch in range(num_epochs):
        # Corrected function call
        loss = compute_loss_and_grads(model, X, f, lambda_l1, lambda_l2)
        loss_value, _ = loss

        # Training step
        train_loss_value, grads = compute_train_loss_and_grads(model, X_train, f_train, lambda_l1, lambda_l2)
        optimizer.apply_gradients(zip(grads, model.trainable_variables))

        # Validation loss
        val_loss = compute_loss(model, X_val, f_val, lambda_l1, lambda_l2, training=False)

        if val_loss < best_val_loss:
            best_val_loss = val_loss
            epochs_without_improvement = 0
        else:
            epochs_without_improvement += 1

        if epochs_without_improvement >= patience:
            print("Early stopping triggered.")
            break
        
        # Record loss values
        train_loss_values.append(train_loss_value.numpy())
        val_loss_values.append(val_loss.numpy())
        loss_values.append(loss_value.numpy())

        print(f'Epoch {epoch + 1}: Full Dataset Loss = {loss_value:.4f}, Training Loss = {train_loss_value:.4f}, Validation Loss = {val_loss:.4f}')

    return loss_values, train_loss_values, val_loss_values


def plot_loss_curves(loss_values, train_loss_values, val_loss_values):
    plt.figure(figsize=(12, 6))
    
    # Plot full dataset loss
    plt.plot(range(len(loss_values)), loss_values, label='Full Dataset Loss', color='blue')
    
    # Plot training loss
    plt.plot(range(len(train_loss_values)), train_loss_values, label='Training Loss', color='red')

    # Plot validation loss
    plt.plot(range(len(val_loss_values)), val_loss_values, label='Validation Loss', color='green')
    
    max_loss = max(loss_values)
    min_loss = min(loss_values)
    print(f'Max Loss: {max_loss}')
    print(f'Min Loss: {min_loss}')
    
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid()
    plt.show()

def main():
    A, f = load_data()
    X = preprocess_data()
    X_train, X_val, f_train, f_val = train_test_split(X.numpy(), f.numpy(), test_size=0.2, random_state=42)
    X_train, X_val = tf.constant(X_train, dtype=tf.float32), tf.constant(X_val, dtype=tf.float32)
    f_train, f_val = tf.constant(f_train, dtype=tf.float32), tf.constant(f_val, dtype=tf.float32)
    
    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(
        initial_learning_rate=0.0005,
        decay_steps=100,
        decay_rate=0.95,
        staircase=True
    )
    optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)

    # Train and evaluate with early stopping
    loss_values, train_loss_values, val_loss_values = train_and_evaluate_mse_with_early_stopping(
        model, X, f, X_train, f_train, X_val, f_val, optimizer)
    
    # Plot loss curves
    plot_loss_curves(loss_values, train_loss_values, val_loss_values)


    # Calculate and print final predictions
    final_predictions = model(X, training=False).numpy()
    print("\nFinal Predictions on the full dataset:\n", final_predictions)

    mse = np.mean(np.square(f.numpy() - final_predictions))
    print("\nMean Squared Error (MSE):", mse)


    full_dataset_loss = compute_loss(model, X, f, lambda_l1=0.000001, lambda_l2=0.000009, training=False).numpy()
    print("\nFull Dataset Loss:", full_dataset_loss)


    # Calculate column sums
    column_sums = np.sum(final_predictions, axis=0)
    print("\nColumn Sums:")
    print(column_sums)

    # Categorization
    categories = {
        "[0, 5)": [],
        "[5, 10)": [],
        "[10, 15)": [],
        "[15, 20]": []
    }

    for i, sum_value in enumerate(column_sums):
        if 0 <= sum_value < 5:
            categories["[0, 5)"].append(i)
        elif 5 <= sum_value < 10:
            categories["[5, 10)"].append(i)
        elif 10 <= sum_value < 15:
            categories["[10, 15)"].append(i)
        elif 15 <= sum_value <= 20:
            categories["[15, 20]"].append(i)

    # Print indices by category
    print("\nRow Indices by Category:")
    for category, indices in categories.items():
        print(f"{category}: {indices}")
    
    # Count the number of indices in each category
    category_counts = [len(indices) for indices in categories.values()]

    # Define pie chart colors
    colors = ['#ff9999', '#66b3ff', '#99ff99', '#ffcc99']

    # Plot the pie chart and improve aesthetics
    fig, ax = plt.subplots(figsize=(10, 8))  # Increase the overall size of the chart
    wedges, texts, autotexts = ax.pie(
        category_counts,
        labels=None,  # Do not use labels
        autopct='%1.1f%%',  # Show percentages
        startangle=140,
        colors=colors
    )

    # Adjust the font size of the percentage text
    for autotext in autotexts:
        autotext.set_fontsize(18)  # Adjust the font size of the percentages

    # Add legend (optional)
    ax.legend(
        wedges,
        categories.keys(),
        title="Categories",
        loc="center left",
        bbox_to_anchor=(1, 0, 0.5, 1),
        fontsize=12
    )

    plt.axis('equal')  # Ensure the pie chart is a circle
    plt.tight_layout()  # 自动调整子绘图参数以填充图形区域
    plt.show()

if __name__ == "__main__":
    main()
